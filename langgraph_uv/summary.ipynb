{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afcb5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import fitz  # pymupdf\n",
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# LangGraph 관련 라이브러리\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828a827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97fa9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 텍스트 추출 및 청킹 ===\n",
    "def extract_text_with_fitz(pdf_path):\n",
    "    \"\"\"PyMuPDF로 텍스트 추출 - 한글 처리 개선\"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        print(f\"PDF 파일: {pdf_path}\")\n",
    "        print(f\"총 페이지 수: {len(doc)}\")\n",
    "        \n",
    "        full_text = \"\"\n",
    "        \n",
    "        for page_num in range(len(doc)):\n",
    "            print(f\"페이지 {page_num + 1} 처리 중...\")\n",
    "            page = doc[page_num]\n",
    "            \n",
    "            # 텍스트 추출\n",
    "            text = page.get_text()\n",
    "            \n",
    "            if text and text.strip():\n",
    "                # 한글 처리 및 텍스트 정리\n",
    "                text = text.replace('\\x00', '')  # null 문자 제거\n",
    "                text = text.replace('\\ufeff', '')  # BOM 제거\n",
    "                text = text.replace('\\r\\n', '\\n')  # 줄바꿈 정리\n",
    "                text = text.replace('\\r', '\\n')\n",
    "                \n",
    "                print(f\"  페이지 {page_num + 1}: {len(text)} 글자 추출\")\n",
    "                print(f\"  첫 50글자: {text[:50]}\")\n",
    "                \n",
    "                full_text += text + \"\\n\\n\"  # 페이지 구분\n",
    "            else:\n",
    "                print(f\"  페이지 {page_num + 1}: 텍스트 없음\")\n",
    "        \n",
    "        doc.close()\n",
    "        print(f\"\\n총 추출된 텍스트: {len(full_text)} 글자\")\n",
    "        return full_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"PyMuPDF 오류: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def chunk_text(text, chunk_size=2000, overlap=100):\n",
    "    \"\"\"텍스트를 청크로 나누는 함수\"\"\"\n",
    "    if not text.strip():\n",
    "        print(\"빈 텍스트입니다.\")\n",
    "        return []\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end].strip()\n",
    "        \n",
    "        if chunk:  # 빈 청크가 아닌 경우만 추가\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        start = end - overlap\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9da585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 벡터 스토어 관련 함수들 ===\n",
    "def search_documents_openai(query, index, embedding_model, chunks, metadatas, k=3):\n",
    "    \"\"\"OpenAI 임베딩을 사용한 문서 검색\"\"\"\n",
    "    try:\n",
    "        # 쿼리를 임베딩으로 변환\n",
    "        query_embedding = embedding_model.embed_query(query)\n",
    "        query_embedding = np.array([query_embedding]).astype('float32')\n",
    "        \n",
    "        # FAISS로 유사한 문서 검색\n",
    "        distances, indices = index.search(query_embedding, k)\n",
    "        \n",
    "        # 결과 포맷팅\n",
    "        results = []\n",
    "        for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "            if idx < len(chunks):  # 유효한 인덱스인지 확인\n",
    "                results.append({\n",
    "                    'chunk_id': idx,\n",
    "                    'content': chunks[idx],\n",
    "                    'score': 1.0 - (distance / 2.0),  # 거리를 유사도로 변환\n",
    "                    'metadata': metadatas[idx] if idx < len(metadatas) else {}\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"검색 오류: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_vectorstore_openai(index, chunks, metadatas, pdf_filename, save_name=\"pdf_openai_vectors\"):\n",
    "    \"\"\"벡터 스토어 저장\"\"\"\n",
    "    try:\n",
    "        # FAISS 인덱스 저장\n",
    "        faiss.write_index(index, f'{save_name}_vectors.index')\n",
    "        \n",
    "        # 청크와 메타데이터 저장\n",
    "        with open(f'{save_name}_data.pkl', 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'chunks': chunks,\n",
    "                'metadatas': metadatas,\n",
    "                'pdf_filename': pdf_filename,\n",
    "                'chunk_count': len(chunks),\n",
    "                'embedding_model': 'text-embedding-3-large',\n",
    "                'embedding_type': 'openai'\n",
    "            }, f)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"저장 오류: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_faiss_vectorstore_openai(chunks, pdf_filename, save_name=\"pdf_openai_vectors\"):\n",
    "    \"\"\"청크들을 FAISS 벡터 스토어로 변환하고 자동 저장 (OpenAI 임베딩 사용)\"\"\"\n",
    "    if not chunks:\n",
    "        print(\"청크가 없습니다.\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    print(\"OpenAI 임베딩 모델 로드 중...\")\n",
    "    embedding = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "    \n",
    "    print(f\"임베딩 생성 중... ({len(chunks)}개 청크)\")\n",
    "    print(\"OpenAI API 호출 중이므로 시간이 걸릴 수 있습니다...\")\n",
    "    \n",
    "    try:\n",
    "        # 청크들을 임베딩으로 변환\n",
    "        embeddings = embedding.embed_documents(chunks)\n",
    "        embeddings = np.array(embeddings).astype('float32')\n",
    "        \n",
    "        print(f\"임베딩 완료! 차원: {embeddings.shape[1]}, 개수: {embeddings.shape[0]}\")\n",
    "        \n",
    "        # FAISS 인덱스 생성\n",
    "        dimension = embeddings.shape[1]\n",
    "        index = faiss.IndexFlatL2(dimension)  # L2 거리 기반 인덱스\n",
    "        index.add(embeddings)\n",
    "        \n",
    "        # 메타데이터 생성\n",
    "        metadatas = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            metadatas.append({\n",
    "                'chunk_id': i,\n",
    "                'source': pdf_filename,\n",
    "                'chunk_size': len(chunk),\n",
    "                'preview': chunk[:100] + \"...\" if len(chunk) > 100 else chunk\n",
    "            })\n",
    "        \n",
    "        print(f\"FAISS 벡터 스토어 생성 완료! {index.ntotal}개 벡터 저장됨\")\n",
    "        \n",
    "        # 자동 저장\n",
    "        print(\"벡터 스토어를 자동 저장 중...\")\n",
    "        if save_vectorstore_openai(index, chunks, metadatas, pdf_filename, save_name):\n",
    "            print(\"✓ 자동 저장 완료!\")\n",
    "        else:\n",
    "            print(\"⚠️  자동 저장 실패\")\n",
    "        \n",
    "        return index, embedding, chunks, metadatas\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"임베딩 생성 오류: {e}\")\n",
    "        print(\"OpenAI API 키가 설정되어 있는지 확인해주세요.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def load_or_create_vectorstore(chunks, pdf_filename, save_name=\"pdf_openai_vectors\"):\n",
    "    \"\"\"벡터 스토어가 있으면 로드하고, 없으면 새로 생성하는 함수\"\"\"\n",
    "    index_file = f'{save_name}_vectors.index'\n",
    "    data_file = f'{save_name}_data.pkl'\n",
    "    \n",
    "    # 저장된 파일들이 모두 존재하는지 확인\n",
    "    if os.path.exists(index_file) and os.path.exists(data_file):\n",
    "        print(\"기존 벡터 스토어를 찾았습니다. 로드 중...\")\n",
    "        \n",
    "        try:\n",
    "            # 저장된 데이터 로드\n",
    "            index = faiss.read_index(index_file)\n",
    "            \n",
    "            with open(data_file, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            # 저장된 PDF 파일명과 현재 파일명 비교\n",
    "            if data['pdf_filename'] == pdf_filename:\n",
    "                print(\"✓ 동일한 PDF 파일의 벡터 스토어 로드 성공!\")\n",
    "                \n",
    "                # OpenAI 임베딩 모델 로드\n",
    "                embedding_model = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "                \n",
    "                print(f\"- 벡터 개수: {index.ntotal}\")\n",
    "                print(f\"- 청크 개수: {data['chunk_count']}\")\n",
    "                print(f\"- 원본 파일: {data['pdf_filename']}\")\n",
    "                print(f\"- 임베딩 모델: {data.get('embedding_model', '정보 없음')}\")\n",
    "                \n",
    "                return index, embedding_model, data['chunks'], data['metadatas']\n",
    "            else:\n",
    "                print(f\"⚠️  다른 PDF 파일의 벡터 스토어입니다.\")\n",
    "                print(f\"   저장된 파일: {data['pdf_filename']}\")\n",
    "                print(f\"   현재 파일: {pdf_filename}\")\n",
    "                print(\"   새로운 벡터 스토어를 생성합니다...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  벡터 스토어 로드 중 오류 발생: {e}\")\n",
    "            print(\"   새로운 벡터 스토어를 생성합니다...\")\n",
    "    \n",
    "    else:\n",
    "        print(\"저장된 벡터 스토어를 찾을 수 없습니다. 새로 생성합니다...\")\n",
    "    \n",
    "    # 새로운 벡터 스토어 생성\n",
    "    print(\"\\n=== 새로운 벡터 스토어 생성 ===\")\n",
    "    return create_faiss_vectorstore_openai(chunks, pdf_filename, save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60106820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 상태 정의 ===\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n",
    "    user_query: str\n",
    "    search_results: List[Dict]\n",
    "    summary: str\n",
    "    tool_calls: List[Dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2cad229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 전역 변수들 ===\n",
    "# 전역 변수로 벡터 스토어 관련 객체들을 저장\n",
    "vector_store_data = {\n",
    "    'index': None,\n",
    "    'embedding_model': None,\n",
    "    'chunks': None,\n",
    "    'metadatas': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e681d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 도구 정의 ===\n",
    "@tool\n",
    "def search_pdf_documents(query: str, k: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    PDF 문서에서 관련 내용을 검색합니다.\n",
    "    \n",
    "    Args:\n",
    "        query: 검색할 키워드나 질문\n",
    "        k: 반환할 결과 개수 (기본값: 3)\n",
    "    \n",
    "    Returns:\n",
    "        검색된 문서 내용들\n",
    "    \"\"\"\n",
    "    if vector_store_data['index'] is None:\n",
    "        return \"벡터 스토어가 준비되지 않았습니다. 먼저 PDF를 처리해주세요.\"\n",
    "    \n",
    "    try:\n",
    "        # 검색 실행\n",
    "        results = search_documents_openai(\n",
    "            query, \n",
    "            vector_store_data['index'], \n",
    "            vector_store_data['embedding_model'], \n",
    "            vector_store_data['chunks'], \n",
    "            vector_store_data['metadatas'], \n",
    "            k\n",
    "        )\n",
    "        \n",
    "        if not results:\n",
    "            return f\"'{query}'에 대한 검색 결과가 없습니다.\"\n",
    "        \n",
    "        # 검색 결과를 문자열로 포맷팅\n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results):\n",
    "            formatted_results.append(\n",
    "                f\"[검색결과 {i+1}]\\n\"\n",
    "                f\"유사도: {result['score']:.4f}\\n\"\n",
    "                f\"내용: {result['content'][:500]}{'...' if len(result['content']) > 500 else ''}\\n\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\\n\".join(formatted_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"검색 중 오류 발생: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def summarize_content(content: str, focus: str = \"general\") -> str:\n",
    "    \"\"\"\n",
    "    주어진 내용을 요약합니다.\n",
    "    \n",
    "    Args:\n",
    "        content: 요약할 내용\n",
    "        focus: 요약 초점 (\"general\", \"key_points\", \"technical\", \"brief\")\n",
    "    \n",
    "    Returns:\n",
    "        요약된 내용\n",
    "    \"\"\"\n",
    "    if not content.strip():\n",
    "        return \"요약할 내용이 없습니다.\"\n",
    "    \n",
    "    # OpenAI LLM 모델 사용\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    \n",
    "    focus_prompts = {\n",
    "        \"general\": \"다음 내용을 전반적으로 요약해주세요:\",\n",
    "        \"key_points\": \"다음 내용에서 핵심 포인트들만 정리해주세요:\",\n",
    "        \"technical\": \"다음 내용에서 기술적인 부분을 중심으로 요약해주세요:\",\n",
    "        \"brief\": \"다음 내용을 간단히 한 문단으로 요약해주세요:\"\n",
    "    }\n",
    "    \n",
    "    prompt = focus_prompts.get(focus, focus_prompts[\"general\"])\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([\n",
    "            HumanMessage(content=f\"{prompt}\\n\\n{content}\")\n",
    "        ])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"요약 중 오류 발생: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_document_info() -> str:\n",
    "    \"\"\"\n",
    "    현재 로드된 PDF 문서의 정보를 반환합니다.\n",
    "    \n",
    "    Returns:\n",
    "        문서 정보\n",
    "    \"\"\"\n",
    "    if vector_store_data['chunks'] is None:\n",
    "        return \"로드된 문서가 없습니다.\"\n",
    "    \n",
    "    total_chars = sum(len(chunk) for chunk in vector_store_data['chunks'])\n",
    "    \n",
    "    return f\"\"\"\n",
    "현재 로드된 문서 정보:\n",
    "- 파일명: {vector_store_data.get('pdf_filename', '알 수 없음')}\n",
    "- 총 청크 수: {len(vector_store_data['chunks'])}\n",
    "- 총 글자 수: {total_chars:,}\n",
    "- 평균 청크 크기: {total_chars // len(vector_store_data['chunks']):,} 글자\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bc3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 에이전트 노드 함수들 ===\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"다음 단계를 결정하는 함수\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # 도구 호출이 있으면 도구 실행\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # 그렇지 않으면 종료\n",
    "    return END\n",
    "\n",
    "def call_model(state: AgentState) -> AgentState:\n",
    "    \"\"\"LLM 모델 호출\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # 시스템 프롬프트\n",
    "    system_prompt = \"\"\"\n",
    "당신은 PDF 문서 검색 및 요약 전문 에이전트입니다.\n",
    "\n",
    "사용 가능한 도구들:\n",
    "1. search_pdf_documents: PDF에서 관련 내용 검색\n",
    "2. summarize_content: 내용 요약\n",
    "3. get_document_info: 문서 정보 조회\n",
    "\n",
    "사용자의 질문에 따라 적절한 도구를 사용하여 답변하세요:\n",
    "- 특정 내용을 찾고 싶다면 search_pdf_documents를 사용\n",
    "- 검색된 내용을 요약하고 싶다면 summarize_content를 사용\n",
    "- 문서 정보가 궁금하다면 get_document_info를 사용\n",
    "\n",
    "항상 한국어로 친절하고 정확하게 답변해주세요.\n",
    "\"\"\"\n",
    "    \n",
    "    # 시스템 메시지가 없다면 추가\n",
    "    if not messages or not any(hasattr(msg, 'content') and system_prompt in str(msg.content) for msg in messages[:1]):\n",
    "        messages = [HumanMessage(content=system_prompt)] + messages\n",
    "    \n",
    "    # LLM 호출\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "    llm_with_tools = llm.bind_tools([search_pdf_documents, summarize_content, get_document_info])\n",
    "    \n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    return {\"messages\": messages + [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f37272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 노드 생성\n",
    "tools = [search_pdf_documents, summarize_content, get_document_info]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "def call_tools(state: AgentState) -> AgentState:\n",
    "    \"\"\"도구 실행 - ToolNode를 사용한 새로운 방식\"\"\"\n",
    "    return tool_node.invoke(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e37b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 에이전트 생성 ===\n",
    "def create_pdf_agent():\n",
    "    \"\"\"PDF 검색 요약 에이전트 생성\"\"\"\n",
    "    \n",
    "    # 그래프 생성\n",
    "    graph_builder = StateGraph(AgentState)\n",
    "\n",
    "    # 노드 추가\n",
    "    graph_builder.add_node(\"agent\", call_model)\n",
    "    graph_builder.add_node(\"tools\", call_tools)\n",
    "\n",
    "    # 시작점 설정\n",
    "    graph_builder.set_entry_point(\"agent\")\n",
    "\n",
    "    # 조건부 엣지 추가\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"tools\": \"tools\",\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 도구에서 다시 에이전트로\n",
    "    graph_builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    # 그래프 컴파일\n",
    "    graph = graph_builder.compile()\n",
    "\n",
    "    return graph\n",
    "\n",
    "# === 실행 함수들 ===\n",
    "def run_pdf_agent(user_query: str, pdf_agent) -> str:\n",
    "    \"\"\"PDF 에이전트 실행\"\"\"\n",
    "    \n",
    "    # 초기 상태\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=user_query)],\n",
    "        \"user_query\": user_query,\n",
    "        \"search_results\": [],\n",
    "        \"summary\": \"\",\n",
    "        \"tool_calls\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # 에이전트 실행\n",
    "        result = pdf_agent.invoke(initial_state)\n",
    "        \n",
    "        # 최종 응답 추출\n",
    "        final_message = result[\"messages\"][-1]\n",
    "        if hasattr(final_message, 'content'):\n",
    "            return final_message.content\n",
    "        else:\n",
    "            return str(final_message)\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"에이전트 실행 중 오류 발생: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42a5a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_pdf_agent(pdf_agent):\n",
    "    \"\"\"대화형 PDF 에이전트\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🤖 PDF 검색 요약 에이전트\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"• '종료', 'quit', 'exit'를 입력하면 종료됩니다\")\n",
    "    print(\"• 예시 질문:\")\n",
    "    print(\"  - '교통약자에 대해 검색해서 요약해줘'\")\n",
    "    print(\"  - '고령자 정책 관련 내용을 찾아줘'\")\n",
    "    print(\"  - '문서 정보를 알려줘'\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\n💬 질문을 입력하세요: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['종료', 'quit', 'exit', 'q']:\n",
    "                print(\"에이전트를 종료합니다. 👋\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            print(\"\\n🤖 에이전트가 작업 중입니다...\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # 에이전트 실행\n",
    "            response = run_pdf_agent(user_input, pdf_agent)\n",
    "            \n",
    "            print(f\"\\n🎯 답변:\\n{response}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n에이전트를 종료합니다. 👋\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "150f8747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PDF 텍스트 추출 ===\n",
      "PDF 파일: 2024-PR-15.pdf\n",
      "총 페이지 수: 127\n",
      "페이지 1 처리 중...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m         interactive_pdf_agent(pdf_agent)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== PDF 텍스트 추출 ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m full_text \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_with_fitz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m full_text:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✗ 텍스트 추출 실패\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mextract_text_with_fitz\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     13\u001b[0m page \u001b[38;5;241m=\u001b[39m doc[page_num]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 텍스트 추출\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mand\u001b[39;00m text\u001b[38;5;241m.\u001b[39mstrip():\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# 한글 처리 및 텍스트 정리\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# null 문자 제거\u001b[39;00m\n",
      "File \u001b[1;32mc:\\AI_Prompt\\workspace\\ai_agent_work2\\langgraph_uv\\.venv\\Lib\\site-packages\\pymupdf\\utils.py:1002\u001b[0m, in \u001b[0;36mget_text\u001b[1;34m(page, option, clip, flags, textpage, sort, delimiters, tolerance)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     t \u001b[38;5;241m=\u001b[39m tp\u001b[38;5;241m.\u001b[39mextractXHTML()\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1002\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractText\u001b[49m\u001b[43m(\u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m textpage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m tp\n",
      "File \u001b[1;32mc:\\AI_Prompt\\workspace\\ai_agent_work2\\langgraph_uv\\.venv\\Lib\\site-packages\\pymupdf\\__init__.py:12267\u001b[0m, in \u001b[0;36mTextPage.extractText\u001b[1;34m(self, sort)\u001b[0m\n\u001b[0;32m  12265\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return simple, bare text on the page.\"\"\"\u001b[39;00m\n\u001b[0;32m  12266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort:\n\u001b[1;32m> 12267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extractText\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m  12268\u001b[0m blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextractBLOCKS()[:]\n\u001b[0;32m  12269\u001b[0m blocks\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m b: (b[\u001b[38;5;241m3\u001b[39m], b[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\AI_Prompt\\workspace\\ai_agent_work2\\langgraph_uv\\.venv\\Lib\\site-packages\\pymupdf\\__init__.py:12073\u001b[0m, in \u001b[0;36mTextPage._extractText\u001b[1;34m(self, format_)\u001b[0m\n\u001b[0;32m  12071\u001b[0m     JM_print_stext_page_as_text(res, this_tpage)\n\u001b[0;32m  12072\u001b[0m out\u001b[38;5;241m.\u001b[39mfz_close_output()\n\u001b[1;32m> 12073\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mJM_EscapeStrFromBuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  12074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[1;32mc:\\AI_Prompt\\workspace\\ai_agent_work2\\langgraph_uv\\.venv\\Lib\\site-packages\\pymupdf\\__init__.py:14701\u001b[0m, in \u001b[0;36mJM_EscapeStrFromBuffer\u001b[1;34m(buff)\u001b[0m\n\u001b[0;32m  14699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m  14700\u001b[0m s \u001b[38;5;241m=\u001b[39m mupdf\u001b[38;5;241m.\u001b[39mfz_buffer_extract_copy(buff)\n\u001b[1;32m> 14701\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43mPyUnicode_DecodeRawUnicodeEscape\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m  14702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "File \u001b[1;32mc:\\AI_Prompt\\workspace\\ai_agent_work2\\langgraph_uv\\.venv\\Lib\\site-packages\\pymupdf\\__init__.py:17448\u001b[0m, in \u001b[0;36mPyUnicode_DecodeRawUnicodeEscape\u001b[1;34m(s, errors)\u001b[0m\n\u001b[0;32m  17446\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m  17447\u001b[0m     rc \u001b[38;5;241m=\u001b[39m s[:]\n\u001b[1;32m> 17448\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw_unicode_escape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  17449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\__init__.py:99\u001b[0m, in \u001b[0;36msearch_function\u001b[1;34m(encoding)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# Import is absolute to prevent the possibly malicious import of a\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# module with side-effects that is not in the 'encodings' package.\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28m__import__\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencodings.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m modname, fromlist\u001b[38;5;241m=\u001b[39m_import_tail,\n\u001b[0;32m    100\u001b[0m                      level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# ImportError may occur because 'encodings.(modname)' does not exist,\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# or because it imports a name that does not exist (see mbcs and oem)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1138\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1078\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1507\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1479\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1615\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === 메인 실행 ===\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    # 1. PDF 텍스트 추출\n",
    "    pdf_file = \"2024-PR-15.pdf\"\n",
    "    \n",
    "    if not os.path.exists(pdf_file):\n",
    "        print(f\"✗ PDF 파일을 찾을 수 없습니다: {pdf_file}\")\n",
    "        return\n",
    "    \n",
    "    print(\"=== PDF 텍스트 추출 ===\")\n",
    "    full_text = extract_text_with_fitz(pdf_file)\n",
    "    \n",
    "    if not full_text:\n",
    "        print(\"✗ 텍스트 추출 실패\")\n",
    "        return\n",
    "    \n",
    "    print(\"✓ 텍스트 추출 성공!\")\n",
    "    \n",
    "    # 2. 텍스트 청킹\n",
    "    print(\"\\n=== 텍스트 청킹 ===\")\n",
    "    chunks = chunk_text(full_text)\n",
    "    print(f\"✓ 청킹 완료: {len(chunks)}개 청크\")\n",
    "    \n",
    "    # 3. 벡터 스토어 생성/로드\n",
    "    print(\"\\n=== 벡터 스토어 처리 ===\")\n",
    "    index, embedding_model, chunks, metadatas = load_or_create_vectorstore(\n",
    "        chunks, \n",
    "        pdf_file, \n",
    "        save_name=\"my_pdf_vectors\"\n",
    "    )\n",
    "    \n",
    "    if index is None:\n",
    "        print(\"✗ 벡터 스토어 준비 실패\")\n",
    "        return\n",
    "    \n",
    "    print(\"✓ 벡터 스토어 준비 완료!\")\n",
    "    \n",
    "    # 4. 전역 변수에 저장\n",
    "    vector_store_data['index'] = index\n",
    "    vector_store_data['embedding_model'] = embedding_model\n",
    "    vector_store_data['chunks'] = chunks\n",
    "    vector_store_data['metadatas'] = metadatas\n",
    "    vector_store_data['pdf_filename'] = pdf_file\n",
    "    \n",
    "    # 5. 에이전트 생성\n",
    "    print(\"\\n=== PDF 에이전트 생성 ===\")\n",
    "    pdf_agent = create_pdf_agent()\n",
    "    print(\"✓ PDF 에이전트 생성 완료!\")\n",
    "    \n",
    "    # 6. 테스트 실행\n",
    "    test_query = \"문서 정보를 알려줘\"\n",
    "    print(f\"\\n🧪 테스트 실행: {test_query}\")\n",
    "    result = run_pdf_agent(test_query, pdf_agent)\n",
    "    print(f\"결과: {result}\")\n",
    "    \n",
    "    # 7. 대화형 실행\n",
    "    print(\"\\n🚀 대화형 에이전트를 시작하시겠습니까? (y/n)\")\n",
    "    if input(\"입력: \").lower() in ['y', 'yes', '네', 'ㅇ']:\n",
    "        interactive_pdf_agent(pdf_agent)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-uv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
